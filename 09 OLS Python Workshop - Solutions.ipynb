{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workshop - OLS Python\n",
    "\n",
    "In this workshop, we are going to:\n",
    "\n",
    "1. perform backward selection on the class data set\n",
    "   1. fit the full model with $\\%\\Delta rGDP$ as the label\n",
    "   2. remove the feature with the highest p-value\n",
    "   3. refit the model\n",
    "   4. repeat steps B. and C. until all features have p-values below 0.05\n",
    "2. evaluatate the model performance\n",
    "\n",
    "*Do not use interactions or polynomial terms in this workshop.*\n",
    "\n",
    "# Preliminaries\n",
    "\n",
    "- Load any necessary packages and/or functions\n",
    "    * For backward select, I recommend using `statsmodels.api` instead of `statsmodels.formula.api`. Your choice.\n",
    "- Load in the class data\n",
    "- Define `x` and `y`\n",
    "- Create a train-test split with\n",
    "    * training size of two-thirds\n",
    "    * random state of 490"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/johnj/Documents/Data/aml in econ 02 spring 2021/class data/class_data.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-7d95748b0654>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# To load in the pickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:/Users/johnj/Documents/Data/aml in econ 02 spring 2021/class data/class_data.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[1;34m(filepath_or_buffer, compression)\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcompression\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"infer\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m         \u001b[0mcompression\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m     \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_handle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[1;31m# 1) try standard library Pickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    432\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m             \u001b[1;31m# Binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/johnj/Documents/Data/aml in econ 02 spring 2021/class data/class_data.pkl'"
     ]
    }
   ],
   "source": [
    "# To load in the pickle\n",
    "df = pd.read_pickle('C:/Users/johnj/Documents/Data/aml in econ 02 spring 2021/class data/class_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load in and set up the csv file\n",
    "df = pd.read_csv('C:/Users/johnj/Documents/Data/aml in econ 02 spring 2021/class data/class_data.csv')\n",
    "df.set_index(['fips', 'year', 'GeoName'], inplace = True)\n",
    "df\n",
    "df['year'] = df.index.get_level_values('year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['const', 'density', 'emp_estabs', 'estabs_entry_rate',\n",
       "       'estabs_exit_rate', 'lfpr', 'pop', 'pop_pct_black', 'pop_pct_hisp',\n",
       "       'pos_net_jobs', 'urate_lower', 'urate_similar', 'year_2003',\n",
       "       'year_2004', 'year_2005', 'year_2006', 'year_2007', 'year_2008',\n",
       "       'year_2009', 'year_2010', 'year_2011', 'year_2012', 'year_2013',\n",
       "       'year_2014', 'year_2015', 'year_2016', 'year_2017', 'year_2018'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defining y and x\n",
    "y = df['pct_d_rgdp']\n",
    "x = df.drop(columns = 'pct_d_rgdp')\n",
    "\n",
    "# Creating dummies\n",
    "x = x.join([pd.get_dummies(x['year'], prefix = 'year', drop_first = True),\n",
    "          pd.get_dummies(x['urate_bin'], prefix = 'urate', drop_first = True)]).drop(columns = ['year', 'urate_bin'])\n",
    "x = sm.add_constant(x)\n",
    "\n",
    "# Sorting the columns for output\n",
    "x.sort_index(axis = 'columns', inplace = True)\n",
    "\n",
    "# Dropping un\n",
    "x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size = 2/3,\n",
    "                                                    random_state = 490)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****\n",
    "# Backward Selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Results: Ordinary least squares\n",
      "====================================================================\n",
      "Model:              OLS              Adj. R-squared:     0.041      \n",
      "Dependent Variable: pct_d_rgdp       AIC:                246970.3167\n",
      "Date:               2021-02-23 17:56 BIC:                247155.7953\n",
      "No. Observations:   33889            Log-Likelihood:     -1.2346e+05\n",
      "Df Model:           21               F-statistic:        69.38      \n",
      "Df Residuals:       33867            Prob (F-statistic): 1.65e-289  \n",
      "R-squared:          0.041            Scale:              85.550     \n",
      "--------------------------------------------------------------------\n",
      "                     Coef.  Std.Err.    t     P>|t|   [0.025  0.975]\n",
      "--------------------------------------------------------------------\n",
      "const               -2.1414   0.5048  -4.2422 0.0000 -3.1308 -1.1520\n",
      "emp_estabs          -0.0434   0.0108  -4.0255 0.0001 -0.0645 -0.0223\n",
      "estabs_entry_rate    0.2878   0.0197  14.6260 0.0000  0.2492  0.3263\n",
      "estabs_exit_rate    -0.2135   0.0226  -9.4646 0.0000 -0.2577 -0.1693\n",
      "lfpr                 0.0433   0.0052   8.3381 0.0000  0.0331  0.0534\n",
      "pop_pct_hisp         0.0225   0.0039   5.7863 0.0000  0.0149  0.0301\n",
      "pos_net_jobs         1.1354   0.1091  10.4029 0.0000  0.9215  1.3494\n",
      "urate_lower          1.2342   0.1334   9.2536 0.0000  0.9728  1.4956\n",
      "urate_similar        0.6491   0.1475   4.4017 0.0000  0.3601  0.9382\n",
      "year_2004           -0.5085   0.2339  -2.1739 0.0297 -0.9670 -0.0500\n",
      "year_2006            1.6836   0.2409   6.9874 0.0000  1.2113  2.1558\n",
      "year_2007           -1.5648   0.2314  -6.7612 0.0000 -2.0185 -1.1112\n",
      "year_2008           -1.7170   0.2344  -7.3262 0.0000 -2.1763 -1.2576\n",
      "year_2009           -2.5129   0.2387 -10.5262 0.0000 -2.9808 -2.0450\n",
      "year_2010            0.5159   0.2344   2.2010 0.0277  0.0565  0.9754\n",
      "year_2011           -0.5958   0.2327  -2.5604 0.0105 -1.0518 -0.1397\n",
      "year_2012           -1.8647   0.2357  -7.9128 0.0000 -2.3266 -1.4028\n",
      "year_2014           -1.5355   0.2337  -6.5694 0.0000 -1.9936 -1.0774\n",
      "year_2015           -1.2351   0.2396  -5.1554 0.0000 -1.7047 -0.7656\n",
      "year_2016           -2.7089   0.2369 -11.4366 0.0000 -3.1731 -2.2446\n",
      "year_2017           -1.1367   0.2371  -4.7941 0.0000 -1.6015 -0.6720\n",
      "year_2018           -0.4968   0.2424  -2.0493 0.0404 -0.9719 -0.0216\n",
      "--------------------------------------------------------------------\n",
      "Omnibus:            34634.651     Durbin-Watson:        1.994       \n",
      "Prob(Omnibus):      0.000         Jarque-Bera (JB):     10695929.309\n",
      "Skew:               4.490         Prob(JB):             0.000       \n",
      "Kurtosis:           89.569        Condition No.:        872         \n",
      "====================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit = sm.OLS(y_train, x_train.drop(columns = ['density',\n",
    "                                             'year_2005',\n",
    "                                             'pop_pct_black',\n",
    "                                             'year_2013',\n",
    "                                             'year_2003',\n",
    "                                             'pop'])).fit()\n",
    "print(fit.summary2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**********\n",
    "# Testing\n",
    "\n",
    "Evaluate two RMSEs:\n",
    "\n",
    "1. null model\n",
    "2. backward-selected model\n",
    "\n",
    "Then, determine the percent improvement of the backward-selected modelf from the null model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.403229309446852"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_null = np.sqrt(  np.mean((y_test - np.mean(y_train))**2)  )\n",
    "rmse_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.216942512937903"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_fit = fit.predict(x_test.drop(columns = ['density',\n",
    "                                             'year_2005',\n",
    "                                             'pop_pct_black',\n",
    "                                             'year_2013',\n",
    "                                             'year_2003',\n",
    "                                             'pop']))\n",
    "rmse_fit = np.sqrt(  np.mean((y_test - yhat_fit)**2)  )\n",
    "rmse_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.98%\n"
     ]
    }
   ],
   "source": [
    "print(round((rmse_null - rmse_fit)/rmse_null*100, 2), '%', sep = '')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
